{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Food Recommender System\n",
    "Dataset: Amazon Fine Foods Reviews.\n",
    "\n",
    "Source: https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "Author: Luis Da Silva.\n",
    "\n",
    "Description: \"This dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\"\n",
    "\n",
    "Recommendation systems can be built in a variety of ways. If one knows nothing about the given user then one could simply recommend the most popular or hot items, this is a quite straightforward approach but will often fail to be accurate. A better approach -but requires some data about the user/audience- is to employ either collaborative filtering, which recommends content similar to the one the user has shown interest in, or content-based filtering, which shows content that some other users that seem to have alike preferences rated with high score.\n",
    "\n",
    "In this exercise, I'm implementing a mixture of those two methods by training a Random Forest Regressor to predict the score a user will give to a product s/he hasn't consumed yet. This method is chosen because it is simple enough to be implemented quickly, but complex enough to take advantage of most of the information in the dataset (including text) to produce accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from joblib import dump, load\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, f1_score, mean_squared_error\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(df, var, name):\n",
    "    n = df[var].nunique()\n",
    "    m = df[var].value_counts()\n",
    "    s = df.groupby(var)['Score'].mean()\n",
    "    print('Number of {}: {}'.format(name, n))\n",
    "    print('Reviews')\n",
    "    print('Mean: {:.2f}, std: {:.2f}, max: {}, median: {:.2f}, min: {}'.\\\n",
    "          format(m.mean(), m.std(), m.max(), m.median(), m.min()))\n",
    "    print('Score')\n",
    "    print('Mean: {:.2f}, std: {:.2f}, max: {}, median: {:.2f}, min: {}'.\\\n",
    "          format(s.mean(), s.std(), s.max(), s.median(), s.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Reviews.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time is not in proper format\n",
    "df.Time = pd.to_datetime(df.Time, unit='s')\n",
    "df['Year'] = df.Time.dt.year\n",
    "\n",
    "# Id is useless\n",
    "df.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "# Factorize product and user ids to save memory\n",
    "df.UserId = df.UserId.factorize()[0]\n",
    "df.ProductId = df.ProductId.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductId                  0\n",
       "UserId                     0\n",
       "ProfileName               16\n",
       "HelpfulnessNumerator       0\n",
       "HelpfulnessDenominator     0\n",
       "Score                      0\n",
       "Time                       0\n",
       "Summary                   27\n",
       "Text                       0\n",
       "Year                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95552, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm dropping products and users with 10 reviews or less\n",
    "# I want to avoid memory errors\n",
    "# And their utility may be marginal\n",
    "df = df[df.groupby('ProductId')['ProductId'].transform('count') > 10]\n",
    "df = df[df.groupby('UserId')['UserId'].transform('count') > 10]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6161"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have users rated the same product twice or more?\n",
    "df[['ProductId', 'UserId']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 5049\n",
      "Reviews\n",
      "Mean: 18.92, std: 13.65, max: 291, median: 14.00, min: 11\n",
      "Score\n",
      "Mean: 4.15, std: 0.98, max: 5.0, median: 4.40, min: 1.0\n",
      "*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
      "Number of products: 7883\n",
      "Reviews\n",
      "Mean: 12.12, std: 31.71, max: 369, median: 3.00, min: 1\n",
      "Score\n",
      "Mean: 4.26, std: 0.84, max: 5.0, median: 4.50, min: 1.0\n"
     ]
    }
   ],
   "source": [
    "describe(df, 'UserId', 'users')\n",
    "print('*--'*20)\n",
    "describe(df, 'ProductId', 'products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm planning on getting features from both summary and text\n",
    "df['Full_txt'] = df['Summary'].fillna('') + ' ' + df['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train, test and validation\n",
    "The aim is to train the model into the train dataset, tune hyper parameter with the test dataset and then perform final validation with the validation dataset. This gives a more accurate perception of the real error because the model never gets to see the answers (scores) for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76441, 11) (19111, 11)\n"
     ]
    }
   ],
   "source": [
    "# Split train and validation\n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state = 412)\n",
    "for train_idx, test_idx in sss.split(df, df.Score, df.ProductId):\n",
    "    train = df.iloc[train_idx]\n",
    "    validation = df.iloc[test_idx]\n",
    "    break\n",
    "print(train.shape, validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61152, 11) (15289, 11)\n"
     ]
    }
   ],
   "source": [
    "# Now split train in train and test\n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state = 412)\n",
    "for train_idx, test_idx in sss.split(train, train.Score, train.ProductId):\n",
    "    test = train.iloc[test_idx]\n",
    "    train = train.iloc[train_idx]\n",
    "    break\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 5049\n",
      "Reviews\n",
      "Mean: 12.11, std: 8.97, max: 198, median: 10.00, min: 2\n",
      "Score\n",
      "Mean: 4.14, std: 0.99, max: 5.0, median: 4.40, min: 1.0\n",
      "*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
      "Number of products: 6891\n",
      "Reviews\n",
      "Mean: 8.87, std: 21.60, max: 236, median: 2.00, min: 1\n",
      "Score\n",
      "Mean: 4.25, std: 0.89, max: 5.0, median: 4.50, min: 1.0\n",
      "*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
      "Number of users: 4842\n",
      "Reviews\n",
      "Mean: 3.95, std: 3.22, max: 63, median: 3.00, min: 1\n",
      "Score\n",
      "Mean: 4.15, std: 1.07, max: 5.0, median: 4.50, min: 1.0\n",
      "*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--\n",
      "Number of products: 4282\n",
      "Reviews\n",
      "Mean: 4.46, std: 8.19, max: 76, median: 1.00, min: 1\n",
      "Score\n",
      "Mean: 4.26, std: 0.97, max: 5.0, median: 4.60, min: 1.0\n"
     ]
    }
   ],
   "source": [
    "describe(train, 'UserId', 'users')\n",
    "print('*--'*20)\n",
    "describe(train, 'ProductId', 'products')\n",
    "print('*--'*20)\n",
    "describe(validation, 'UserId', 'users')\n",
    "print('*--'*20)\n",
    "describe(validation, 'ProductId', 'products')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text keywords extraction\n",
    "As data has been semi-anonimized, the best description of the product exists in the reviews. By extracting keywords from then, one could obtain useful groups of products. This assumes that, when reviewing, people tend to use certain word when talking about a specific type of product.\n",
    "\n",
    "A very raw version of keyword extraction is being performed here, with no especial tuning being made. Also, no attempt to get a feeling of the whole text instead of just the keywords is being made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I noticed some words I'd like to remove\n",
    "words = ['br', 'john', 'pb', 'pg', 'ck', 'amazon', 'wayyyy', 'come', 'bye']\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words = stop_words.union(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize_text(x, stop_words=stop_words):\n",
    "    # standardize text\n",
    "    x = re.sub('[^a-zA-Z]', ' ', x)\n",
    "    x = x.lower()\n",
    "    \n",
    "    x=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",x)\n",
    "    x=re.sub(\"(\\\\d|\\\\W)+\",\" \",x)\n",
    "    \n",
    "    x = x.split(' ')\n",
    "    ps=PorterStemmer()\n",
    "    lem = WordNetLemmatizer()\n",
    "    x = [lem.lemmatize(word) for word in x if not word in stop_words]\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I only use train dataset in this phase to avoid data leakage\n",
    "train['Full_txt'] = train['Full_txt'].apply(regularize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize words\n",
    "countV=CountVectorizer(max_df=0.8,stop_words=stop_words, max_features=10000, ngram_range=(1,1))\n",
    "X=countV.fit_transform(train['Full_txt'])\n",
    "\n",
    "# Calculate TFIDF\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf.fit(X)\n",
    "feature_names=countV.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to extract most important keywords\n",
    "def sort_matrix(m):\n",
    "    tuples = zip(m.col, m.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_n(names, items, n=10):\n",
    "    sorted_items = items[:n+1]\n",
    " \n",
    "    scores = []\n",
    "    features = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, s in sorted_items:\n",
    "        scores.append(round(s, 3))\n",
    "        features.append(names[idx])\n",
    "\n",
    "    return dict(zip(features, scores)) \n",
    "\n",
    "def keywords_from_doc(doc, tfidf, n=5):\n",
    "    tfidf_vector=tfidf.transform(countV.transform(doc))\n",
    "    sorted_items=sort_matrix(tfidf_vector.tocoo())\n",
    "    return extract_n(feature_names,sorted_items,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dict with the keywords of each product\n",
    "keywords_per_product = {}\n",
    "ids = train['ProductId'].unique()\n",
    "for i in ids:\n",
    "    mask = train['ProductId'] == i\n",
    "    doc = train[mask]['Full_txt'].values\n",
    "    keywords = keywords_from_doc(doc, tfidf, 5)\n",
    "    keywords_per_product[i] = list(keywords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequency of keywords and only keep the most frequent 5%\n",
    "count = Counter()\n",
    "for v in keywords_per_product.values():\n",
    "    count.update(v)\n",
    "    \n",
    "perc = np.percentile(list(count.values()), 95)\n",
    "keywords = [k for k,v in count.items() if v>=perc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bergamot</th>\n",
       "      <th>chai</th>\n",
       "      <th>earl</th>\n",
       "      <th>grey</th>\n",
       "      <th>food</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>organic</th>\n",
       "      <th>yorkie</th>\n",
       "      <th>chamomile</th>\n",
       "      <th>...</th>\n",
       "      <th>heat</th>\n",
       "      <th>formula</th>\n",
       "      <th>loved</th>\n",
       "      <th>pancake</th>\n",
       "      <th>toddler</th>\n",
       "      <th>really</th>\n",
       "      <th>recommended</th>\n",
       "      <th>sardine</th>\n",
       "      <th>allergy</th>\n",
       "      <th>kernel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65162</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17957</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17576</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27285</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38032</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bergamot  chai  earl  grey  food  cat  dog  organic  yorkie  chamomile  \\\n",
       "65162         1     1     1     1     0    0    0        0       0          0   \n",
       "17957         0     0     0     0     1    1    1        0       0          0   \n",
       "17576         0     0     0     0     0    0    0        1       0          0   \n",
       "27285         0     0     0     0     0    0    0        0       0          0   \n",
       "38032         0     0     0     0     0    1    1        0       1          0   \n",
       "\n",
       "        ...    heat  formula  loved  pancake  toddler  really  recommended  \\\n",
       "65162   ...       0        0      0        0        0       0            0   \n",
       "17957   ...       0        0      0        0        0       0            0   \n",
       "17576   ...       0        0      0        0        0       0            0   \n",
       "27285   ...       0        0      0        0        0       0            0   \n",
       "38032   ...       0        0      0        0        0       0            0   \n",
       "\n",
       "       sardine  allergy  kernel  \n",
       "65162        0        0       0  \n",
       "17957        0        0       0  \n",
       "17576        0        0       0  \n",
       "27285        0        0       0  \n",
       "38032        0        0       0  \n",
       "\n",
       "[5 rows x 321 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHot encode keywords\n",
    "prod_vec = {}\n",
    "for product in train['ProductId'].unique():\n",
    "    vec = []\n",
    "    for keyword in keywords:\n",
    "        if keyword in keywords_per_product[product]:\n",
    "            vec.append(1)\n",
    "        else:\n",
    "            vec.append(0)\n",
    "    prod_vec[product] = vec\n",
    "    \n",
    "prod_features = pd.DataFrame(prod_vec).T\n",
    "prod_features.columns = keywords\n",
    "prod_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keywords per product have been extracted and one-hot encoded. It looks good enough, so I'll just merge it into the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(prod_features, left_on=['ProductId'], right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get aditional features from scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_features(data, group, var, prefix):\n",
    "    g = data.groupby(group)[var]\n",
    "    data[prefix+var+'Mean'] = g.transform('mean')\n",
    "    data[prefix+var+'Std'] = g.transform('std')\n",
    "    data[prefix+var+'Count'] = g.transform('count')\n",
    "    return data\n",
    "\n",
    "train = standard_features(train, 'UserId', 'Score', 'User')\n",
    "train = standard_features(train, 'ProductId', 'Score', 'Product')\n",
    "train = standard_features(train, ['ProductId', 'Year'], 'Score', 'ProductYear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge features to train and validation\n",
    "To avoid data leakage, features are only extracted from train dataset and then merged back into the test and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cols = train.filter(regex='(Product).*').columns\n",
    "user_cols = train.filter(regex='(User).*').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(train[product_cols].groupby('ProductId').mean(), left_on='ProductId', right_index=True, how='left')\n",
    "test = test.merge(train[user_cols].groupby('UserId').mean(), left_on='UserId', right_index=True, how='left')\n",
    "test = test.merge(prod_features, left_on=['ProductId'], right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna(0, inplace=True) # There is no information about NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = validation.merge(train[product_cols].groupby('ProductId').mean(), \n",
    "                              left_on='ProductId', right_index=True, how='left')\n",
    "validation = validation.merge(train[user_cols].groupby('UserId').mean(), \n",
    "                              left_on='UserId', right_index=True, how='left')\n",
    "validation = validation.merge(prod_features, left_on=['ProductId'], \n",
    "                              right_index=True, how='left')\n",
    "validation.fillna(0, inplace=True) # There is no information about NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, tune and validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(model, X_train, X_test, y_train, y_test):\n",
    "    # MSE Scorer\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, X_train, X_test, y_train, y_test, param_grid, rs=542, verbose=False):\n",
    "    # Hyperparameter grid search\n",
    "    if verbose:\n",
    "        total = sum([1 for _ in product(*param_grid.values())])\n",
    "    \n",
    "    combs = product(*param_grid.values())\n",
    "    best_score = np.inf\n",
    "    for i, comb in enumerate(combs):            \n",
    "        params = dict(zip(param_grid.keys(), comb))\n",
    "        model.set_params(**params)\n",
    "        score = scorer(model, X_train, X_test, y_train, y_test)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "            \n",
    "        if verbose:\n",
    "            print('Parameter combination: {}/{}. Score:{:.4f}, best:{:.4f}.'.format(i+1,total, score, best_score))\n",
    "            \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X y\n",
    "cols = train.drop(['ProfileName', 'HelpfulnessNumerator', \n",
    "                   'HelpfulnessDenominator', 'Score', 'Time', 'Year',\n",
    "                  'Summary', 'Text', 'Full_txt', 'UserId', 'ProductId'],\n",
    "                  axis=1).columns\n",
    "X_train = train[cols].fillna(0) #NaNs are in std\n",
    "y_train = train['Score']\n",
    "X_test = test[cols].fillna(0)\n",
    "y_test = test['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0209428715876088\n"
     ]
    }
   ],
   "source": [
    "# Fit the base regressor\n",
    "rf = RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=412)\n",
    "rf.fit(X_train, y_train)\n",
    "preds = rf.predict(X_test)\n",
    "score = mean_squared_error(y_test, preds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested q: 0.05, score: 1.0206. Best score: 1.0206\n",
      "Tested q: 0.10, score: 1.0208. Best score: 1.0206\n",
      "Tested q: 0.15, score: 1.0232. Best score: 1.0206\n",
      "Tested q: 0.20, score: 1.0204. Best score: 1.0204\n",
      "Tested q: 0.25, score: 1.0222. Best score: 1.0204\n",
      "Tested q: 0.30, score: 1.0202. Best score: 1.0202\n",
      "Tested q: 0.35, score: 1.0203. Best score: 1.0202\n",
      "Tested q: 0.40, score: 1.0211. Best score: 1.0202\n",
      "Tested q: 0.45, score: 1.0194. Best score: 1.0194\n",
      "Tested q: 0.50, score: 1.0205. Best score: 1.0194\n",
      "Tested q: 0.55, score: 1.0207. Best score: 1.0194\n",
      "Tested q: 0.60, score: 1.0189. Best score: 1.0189\n",
      "Tested q: 0.65, score: 1.0224. Best score: 1.0189\n",
      "Tested q: 0.70, score: 1.0199. Best score: 1.0189\n",
      "Tested q: 0.75, score: 1.0205. Best score: 1.0189\n",
      "Tested q: 0.80, score: 1.0211. Best score: 1.0189\n",
      "Tested q: 0.85, score: 1.0204. Best score: 1.0189\n",
      "Tested q: 0.90, score: 1.0246. Best score: 1.0189\n",
      "Tested q: 0.95, score: 1.0280. Best score: 1.0189\n",
      "Tested q: 0.56, score: 1.0215. Best score: 1.0189\n",
      "Tested q: 0.57, score: 1.0215. Best score: 1.0189\n",
      "Tested q: 0.58, score: 1.0172. Best score: 1.0172\n",
      "Tested q: 0.59, score: 1.0195. Best score: 1.0172\n",
      "Tested q: 0.60, score: 1.0189. Best score: 1.0172\n",
      "Tested q: 0.61, score: 1.0205. Best score: 1.0172\n",
      "Tested q: 0.62, score: 1.0208. Best score: 1.0172\n",
      "Tested q: 0.63, score: 1.0219. Best score: 1.0172\n",
      "Tested q: 0.64, score: 1.0200. Best score: 1.0172\n"
     ]
    }
   ],
   "source": [
    "# Tune features\n",
    "best_score = score\n",
    "features = X_train.columns\n",
    "fi = rf.feature_importances_\n",
    "lfi = np.log(fi)\n",
    "for q in np.arange(0.05, 1, 0.05):\n",
    "    v = np.exp(np.quantile(lfi, q))\n",
    "    features = X_train.columns[fi>=v]\n",
    "\n",
    "    score = scorer(rf, X_train[features], X_test[features], y_train, y_test)\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_features = features\n",
    "        best_q = q\n",
    "    print('Tested q: {:.2f}, score: {:.4f}. Best score: {:.4f}'.format(q, score, best_score))\n",
    "    \n",
    "for q in np.arange(best_q-0.04, best_q+0.04, 0.01):\n",
    "    if np.isclose(best_q,q):\n",
    "        continue\n",
    "    v = np.exp(np.quantile(lfi, q))\n",
    "    features = X_train.columns[fi>=v]\n",
    "\n",
    "    score = scorer(rf, X_train[features], X_test[features], y_train, y_test)\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_features = features\n",
    "        best_q = q\n",
    "    print('Tested q: {:.2f}, score: {:.4f}. Best score: {:.4f}'.format(q, score, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter combination: 1/45. Score:1.0309, best:1.0309.\n",
      "Parameter combination: 2/45. Score:1.0060, best:1.0060.\n",
      "Parameter combination: 3/45. Score:1.0321, best:1.0060.\n",
      "Parameter combination: 4/45. Score:1.0209, best:1.0060.\n",
      "Parameter combination: 5/45. Score:1.0057, best:1.0057.\n",
      "Parameter combination: 6/45. Score:1.0329, best:1.0057.\n",
      "Parameter combination: 7/45. Score:1.0037, best:1.0037.\n",
      "Parameter combination: 8/45. Score:1.0049, best:1.0037.\n",
      "Parameter combination: 9/45. Score:1.0152, best:1.0037.\n",
      "Parameter combination: 10/45. Score:1.0201, best:1.0037.\n",
      "Parameter combination: 11/45. Score:1.0060, best:1.0037.\n",
      "Parameter combination: 12/45. Score:1.0260, best:1.0037.\n",
      "Parameter combination: 13/45. Score:1.0126, best:1.0037.\n",
      "Parameter combination: 14/45. Score:1.0057, best:1.0037.\n",
      "Parameter combination: 15/45. Score:1.0294, best:1.0037.\n",
      "Parameter combination: 16/45. Score:0.9991, best:0.9991.\n",
      "Parameter combination: 17/45. Score:1.0049, best:0.9991.\n",
      "Parameter combination: 18/45. Score:1.0125, best:0.9991.\n",
      "Parameter combination: 19/45. Score:1.0179, best:0.9991.\n",
      "Parameter combination: 20/45. Score:1.0060, best:0.9991.\n",
      "Parameter combination: 21/45. Score:1.0260, best:0.9991.\n",
      "Parameter combination: 22/45. Score:1.0130, best:0.9991.\n",
      "Parameter combination: 23/45. Score:1.0057, best:0.9991.\n",
      "Parameter combination: 24/45. Score:1.0294, best:0.9991.\n",
      "Parameter combination: 25/45. Score:0.9992, best:0.9991.\n",
      "Parameter combination: 26/45. Score:1.0049, best:0.9991.\n",
      "Parameter combination: 27/45. Score:1.0125, best:0.9991.\n",
      "Parameter combination: 28/45. Score:1.0172, best:0.9991.\n",
      "Parameter combination: 29/45. Score:1.0060, best:0.9991.\n",
      "Parameter combination: 30/45. Score:1.0260, best:0.9991.\n",
      "Parameter combination: 31/45. Score:1.0131, best:0.9991.\n",
      "Parameter combination: 32/45. Score:1.0057, best:0.9991.\n",
      "Parameter combination: 33/45. Score:1.0294, best:0.9991.\n",
      "Parameter combination: 34/45. Score:0.9992, best:0.9991.\n",
      "Parameter combination: 35/45. Score:1.0049, best:0.9991.\n",
      "Parameter combination: 36/45. Score:1.0125, best:0.9991.\n",
      "Parameter combination: 37/45. Score:1.0172, best:0.9991.\n",
      "Parameter combination: 38/45. Score:1.0060, best:0.9991.\n",
      "Parameter combination: 39/45. Score:1.0260, best:0.9991.\n",
      "Parameter combination: 40/45. Score:1.0131, best:0.9991.\n",
      "Parameter combination: 41/45. Score:1.0057, best:0.9991.\n",
      "Parameter combination: 42/45. Score:1.0294, best:0.9991.\n",
      "Parameter combination: 43/45. Score:0.9992, best:0.9991.\n",
      "Parameter combination: 44/45. Score:1.0049, best:0.9991.\n",
      "Parameter combination: 45/45. Score:1.0125, best:0.9991.\n",
      "{'max_depth': 30, 'min_samples_split': 60, 'min_impurity_decrease': 0.0, 'n_jobs': -1, 'random_state': 412, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "param_grid = {'max_depth':[15, 30, 50, 100, None], 'min_samples_split':[2, 30, 60],\n",
    "              'min_impurity_decrease':[0.0, 0.001, 0.0001]}\n",
    "params, score = grid_search(rf, X_train[best_features], X_test[best_features],\n",
    "                            y_train, y_test, param_grid, verbose=True)\n",
    "params['n_jobs']=-1\n",
    "params['random_state']=412\n",
    "params['n_estimators']=200\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate\n",
    "To validate the results, I'm joining train and test data and retraining the model with the given features and hyperparameters. For the sake of simplicity, I'm just joining the two datasets together. A better approach is to update product and user data by recalculating them in the new, bigger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = pd.concat([X_train[best_features], X_test[best_features]])\n",
    "y_pre = pd.concat([y_train, y_test])\n",
    "traintest = pd.concat([train, test], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rfModel.joblib']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(**params)\n",
    "rf.fit(X_pre, y_pre)\n",
    "dump(rf, 'rfModel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6670018689634969\n"
     ]
    }
   ],
   "source": [
    "# Validate\n",
    "X_val = validation[best_features]\n",
    "y_val = validation['Score']\n",
    "preds = rf.predict(X_val)\n",
    "mse = mean_squared_error(y_val, preds)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.58\n",
      "Weighted F1: 0.68\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform into a classification problem by rounding predictions\n",
    "print('Macro F1: {:.2f}'.format(f1_score(y_val, preds.round(), average='macro')))\n",
    "print('Weighted F1: {:.2f}'.format(f1_score(y_val, preds.round(), average='weighted')))\n",
    "sns.heatmap(confusion_matrix(y_val, preds.round()), cmap='bwr', center=0, annot=True, fmt='.0f',\n",
    "           xticklabels=range(1,6), yticklabels=range(1,6))\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.66 MSE in validation data is a surprising result. Given that the best MSE that could be achieved on the training phase was 0.99, the better perfomance on validation means that either the model needed more data to find better patterns, that there is still plenty of room to improve this model or even that validation data was too easy.\n",
    "\n",
    "When translated into a classification problem (by rounding predicted scores), a weighted F1 (accounting for label imbalance) of 68% shows that results may be improved way further. Nevertheless, when one looks at the confusion matrix, most of the mistakes come from neighbour classes (e.g. it predicted a 4 but it was a 5), which are not a terrible mistake. Actually, if one thinks about it, humans don't tend to be 100% consistent when rating things (Daniel Kahneman is famous for theorizing on this), so even for the rater it could be easy to change a 5 for a 4. Therefore, even this simple over-optimistic model could be used in production and it will obtain ok results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend to user\n",
    "Finally, the trained model needs to be used to recommed new products to a given user. To do so, it is necessary to compute the expected score and sort the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user=None, n=10, data=traintest, user_cols=user_cols,\n",
    "              product_cols=product_cols, prod_features=prod_features,\n",
    "              features=best_features, model=rf):\n",
    "    \n",
    "    if user is None:\n",
    "        user = random.choice(test.UserId.unique())\n",
    "        \n",
    "    # Assemble dataset for prediction\n",
    "    mask = data.UserId == user\n",
    "    user_features = data[mask][user_cols].mean()\n",
    "    \n",
    "    included_products = data[mask].ProductId.unique()\n",
    "    mask = data.ProductId.apply(lambda x: x not in included_products)\n",
    "    products = data[mask][product_cols]\n",
    "    \n",
    "    products = products.merge(prod_features, left_on='ProductId', right_index=True, how='left')\n",
    "    for i in user_features.iloc[1:].index:\n",
    "        products[i] = user_features[i]\n",
    "    \n",
    "    # Predict and sort results\n",
    "    preds = model.predict(products[features].fillna(0))\n",
    "    recommended = data[mask][['ProductId']]\n",
    "    recommended['PredScore'] = preds\n",
    "    recommended.drop_duplicates(inplace=True)\n",
    "    recommended = recommended.sort_values('PredScore', ascending=False).iloc[:n]\n",
    "        \n",
    "    print('{} recommended products for User {} with scores:'.format(n, user))\n",
    "    print(recommended.to_string(index=False))\n",
    "    \n",
    "    return recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 recommended products for User 13619 with scores:\n",
      "ProductId  PredScore\n",
      "    59941        5.0\n",
      "    31091        5.0\n",
      "    52016        5.0\n",
      "    60025        5.0\n",
      "    29888        5.0\n",
      "    12851        5.0\n",
      "    13159        5.0\n",
      "    36810        5.0\n",
      "    19900        5.0\n",
      "    69096        5.0\n"
     ]
    }
   ],
   "source": [
    "# Choose a random user and recommend him/her 10 products\n",
    "_ = recommend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 recommended products for User 127 with scores:\n",
      "ProductId  PredScore\n",
      "    34023   3.117628\n",
      "     2273   3.059578\n",
      "    45099   3.047742\n",
      "     3663   3.043650\n",
      "    18090   2.987810\n",
      "    26765   2.982199\n",
      "    18090   2.980657\n",
      "    41583   2.971789\n",
      "    55586   2.967789\n",
      "    41583   2.961824\n",
      "    55586   2.957824\n",
      "    56536   2.944563\n",
      "    46244   2.939315\n",
      "    29789   2.922852\n",
      "    42915   2.920367\n"
     ]
    }
   ],
   "source": [
    "# Recommend 15 products to user 127\n",
    "_ = recommend(127, 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
